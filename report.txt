대규모 동시성 환경을 위한 실시간 동기 쿠폰 발급 아키텍처 설계 보고서


Executive Summary

본 보고서는 100만 명의 잠재적 클라이언트에게 1,000개의 한정된 쿠폰을 실시간으로 발급하는 시스템 아키텍처 설계를 목표로 한다. 이 시스템의 핵심 요구사항은 클라이언트가 쿠폰 발급 요청 시 비동기 대기 없이 즉각적인 성공 또는 실패(Pass/Fail) 응답을 받아야 한다는 점이다. 동시에, 각 사용자는 단 하나의 쿠폰만 발급받을 수 있으며, 시스템은 어떠한 경우에도 총 1,000개의 쿠폰 재고를 초과하여 발급해서는 안 된다는 엄격한 제약 조건을 준수해야 한다.1
이러한 상충될 수 있는 요구사항—즉각적인 동기 응답의 신속성과 데이터 무결성의 엄격함—을 해결하기 위해, 본 보고서는 하이브리드 아키텍처를 제안한다. 이 아키텍처는 속도와 원자성(atomicity)을 보장하는 동기식 인메모리(in-memory) 처리 계층과, 안정성 및 데이터 영속성을 담당하는 비동기식 영구 저장 계층을 전략적으로 결합한다. 이 접근법은 사용자 대면 엔드포인트에서는 동기식 처리의 속도를 제공하면서도, 백엔드에서는 비동기 처리를 통해 시스템의 부하를 분산하고 안정성을 확보하는, 사용자 요구사항의 핵심적인 긴장 관계를 해결하는 최적의 방안이다.
제안된 솔루션은 네 가지 핵심 아키텍처 원칙을 기반으로 구축된다:
선제적 에지 트래픽 관리 (Aggressive Edge Traffic Management): 시스템의 핵심 서비스에 도달하기 전에 대규모 트래픽을 효과적으로 제어하고 분산시켜 과부하를 방지한다.
원자적 인메모리 연산 (Atomic In-Memory Operations): Redis와 Lua 스크립팅을 활용하여 잠금(lock) 없는 고성능 동시성 제어를 구현하고, 병목 현상을 최소화한다.
분리된 영속성 처리 (Decoupled Persistence): 메시지 큐(Message Queue)를 사용하여 즉각적인 동기 응답 로직과 시간이 소요되는 데이터베이스 쓰기 작업을 분리하여 시스템 전체의 응답성을 극대화한다.
복원력 및 고가용성 설계 (Resilience and High Availability): 시스템의 모든 계층에서 장애 발생을 가정하고, 이를 극복할 수 있는 다중화 및 장애 복구 메커니즘을 설계한다.
최종 아키텍처는 클라이언트의 요청이 API 게이트웨이, 로드 밸런서를 거쳐 애플리케이션 서버에 도달하는 흐름으로 시작된다. 애플리케이션 서버는 Redis 클러스터에 대해 단일 원자적 연산을 수행하여 즉시 결과를 반환하고, 성공 시 메시지 큐에 이벤트를 발행한다. 별도의 컨슈머 서비스가 이 이벤트를 구독하여 최종적으로 관계형 데이터베이스(RDBMS)에 발급 내역을 영구적으로 기록하는 구조로 완성된다. 이 하이브리드 모델은 대규모 트래픽 환경에서 신속한 사용자 경험과 데이터의 최종적 일관성을 모두 달성하는 강력하고 실용적인 해결책을 제시한다.

섹션 1: 시스템 아키텍처 개요: 하이브리드 접근법

본 아키텍처의 핵심은 사용자의 요구사항인 '즉각적인 동기 응답'과 '안정적인 데이터 처리'라는 두 가지 목표를 동시에 달성하기 위해 동기식 처리와 비동기식 처리를 결합한 하이브리드 모델을 채택하는 것이다. 이 섹션에서는 전체 시스템의 요청 흐름을 정의하고, 각 구성 요소의 역할과 기술 스택을 명확히 한다.

1.1. 엔드투엔드 요청 흐름: 동기적 속도와 비동기적 안정성


동기식 핵심 경로 (The Synchronous Critical Path)

사용자 경험의 최전선에 있는 동기식 경로는 속도에 초점을 맞춰 설계된다. 클라이언트의 쿠폰 발급 요청은 API 게이트웨이를 통해 시스템에 진입하며, 로드 밸런서에 의해 여러 애플리케이션 서버 중 하나로 라우팅된다. 애플리케이션 서버는 요청을 받자마자 Redis 클러스터를 대상으로 단 한 번의 원자적 연산(Lua 스크립트 실행)을 수행한다. 이 연산의 결과(성공, 중복 참여로 인한 실패, 재고 소진으로 인한 실패)는 즉시 클라이언트에게 HTTP 응답으로 반환된다.3 이 전체 경로는 수십 밀리초(sub-100ms) 내에 완료되도록 설계하여 사용자에게 '즉각적인' 피드백을 제공한다.

비동기식 후처리 경로 (The Asynchronous Post-Processing Path)

Redis 연산이 성공적으로 완료되면, 애플리케이션 서버는 '쿠폰 발급 성공' 이벤트를 메시지 큐에 발행(publish)한 후, 즉시 클라이언트에게 성공 응답을 보낸다. 이 시점에서 동기식 경로는 종료된다. 메시지 큐에 저장된 이벤트는 별도로 운영되는 컨슈머 서비스에 의해 비동기적으로 처리된다. 컨슈머 서비스는 메시지를 구독(consume)하여 쿠폰 발급 내역을 최종 기록 저장소인 관계형 데이터베이스에 영구적으로 기록하는, 상대적으로 시간이 더 소요되는 작업을 수행한다.5 이처럼 동기식 경로와 비동기식 경로를 분리하는 것이 본 아키텍처의 성능을 보장하는 핵심 설계 원칙이다.

하이브리드 모델의 당위성

이 하이브리드 모델은 사용자의 상충되어 보이는 요구사항에 대한 직접적인 해답이다. 클라이언트에게는 마치 모든 과정이 동기적으로 처리되어 데이터베이스에 즉시 기록되는 것처럼 보이는 '환상'을 제공한다.7 실제로는 성능에 큰 영향을 미치는 영속성 관련 작업을 비동기적으로 처리하여 핵심 경로(critical path)에서 분리함으로써, 대규모 동시 요청 상황에서도 높은 처리량과 낮은 지연 시간을 유지할 수 있다.9

1.2. 구성 요소별 책임과 기술 스택

본 아키텍처는 대규모 트래픽을 점진적으로 처리하고 필터링하는 '깔때기(funnel)' 구조로 설계되었다. 각 계층은 유입되는 트래픽의 일부를 처리하거나 걸러내어, 더 민감하고 비용이 많이 드는 후방 계층을 보호하는 역할을 수행한다.
이러한 구조가 도출된 과정은 다음과 같다. 첫째, 100만 클라이언트가 1,000개의 한정된 자원을 두고 경쟁하는 상황은 전형적인 'Thundering Herd' 문제에 해당한다.10 모든 요청을 직접 데이터베이스로 보내는 순진한 접근 방식은 즉각적인 교착 상태(deadlock)나 데이터베이스 서버 다운으로 이어질 것이 자명하다.11 따라서, 첫 번째 설계 원칙은 동기식 핵심 경로에서 데이터베이스를 직접 호출하지 않는 것이다. 이는 Redis와 같은 고성능 인메모리 솔루션의 도입을 필연적으로 만든다.11
둘째, Redis를 사용하더라도 애플리케이션 서버 자체가 과부하에 빠질 수 있다. 이는 시스템의 진입점에서 트래픽을 제어할 필요성을 제기하며, 이 역할을 수행하기 위해 API 게이트웨이가 도입된다.14 API 게이트웨이는 단순한 요청 전달자가 아니라, 속도 제한(Rate Limiting)과 스로틀링(Throttling)을 통해 시스템을 보호하는 능동적인 방어 계층이다.17
셋째, Redis에서 쿠폰이 성공적으로 '획득'된 후, 이 결과는 영구적으로 보존되어야 한다. 만약 API 서버가 직접 RDBMS에 쓰기 작업을 수행한다면, 우리가 피하고자 했던 지연 시간이 다시 발생하게 된다. 이 지점에서 동기식 응답 속도에 대한 요구사항이 데이터베이스 쓰기 작업의 분리를 강제하는 인과 관계가 형성된다. 이 문제를 해결하기 위한 가장 자연스러운 해결책은 메시지 큐를 도입하여, 안정적인 버퍼 역할을 수행하게 하는 것이다.5 이 논리적 흐름은 동기식 응답이라는 핵심 제약 조건이 어떻게 영속성 계층에 대한 하이브리드, 이벤트 기반 아키텍처 채택으로 이어지는지를 명확히 보여준다.

1.3. 아키텍처 구성 요소 및 기술 스택 표

아래 표는 시스템을 구성하는 주요 요소와 각 요소에 권장되는 기술 스택, 그리고 그 선택의 근거를 요약한 것이다. 이 표는 전체 시스템 구조에 대한 빠른 참조를 제공하며, 후속 섹션에서 각 구성 요소에 대한 심층적인 논의의 기반이 된다.

구성 요소
주요 기능
권장 기술
선택 근거 및 주요 자료
API 게이트웨이
트래픽 진입, 속도 제한, 보안, 라우팅
Amazon API Gateway, NGINX Plus, Apache APISIX
대규모 동시 호출 관리, 스로틀링을 통한 백엔드 과부하 방지 14
로드 밸런서
애플리케이션 서버 간 트래픽 분산
AWS Application Load Balancer, HAProxy
애플리케이션 계층의 수평적 확장성 및 고가용성 보장 11
애플리케이션 서버
비즈니스 로직 실행, Redis 연동, 이벤트 발행
Node.js/Go/Java (Spring Boot) on EC2/EKS
상태 비저장(Stateless) 방식의 수평 확장이 가능한 컴퓨팅 계층 12
인메모리 데이터 그리드
원자적 쿠폰 발급, 사용자 중복 참여 확인
Redis Cluster
밀리초 이하의 지연 시간으로 원자적 연산 제공, 동시성 제어의 핵심 13
메시지 큐
동기/비동기 경로 분리, DB 쓰기 작업 버퍼링
Apache Kafka, AWS SQS
데이터 영속성 제공 및 데이터베이스 부하 평탄화(load leveling) 역할 5
컨슈머 서비스
메시지 처리, 데이터베이스 쓰기
Kubernetes Pods, AWS Lambda
데이터 영속화를 위한 독립적이고 확장 가능한 워커(worker) 19
관계형 데이터베이스
최종 기록 저장소(System of Record), 데이터 영속화
PostgreSQL, MySQL (with Replication)
데이터 무결성 보장 및 쿠폰 발급 내역의 영구적 기록 11


섹션 2: 최전선 방어: 'Thundering Herd' 문제 관리

이 섹션에서는 아키텍처의 가장 바깥 계층에 초점을 맞춘다. 이 계층들은 이벤트 시작과 동시에 발생하는 폭발적인 트래픽 급증으로부터 시스템 전체의 생존을 보장하는 데 결정적인 역할을 한다.

2.1. 트래픽 제어기로서의 API 게이트웨이


역할과 중요성

API 게이트웨이는 단순한 프록시가 아니라, 시스템의 첫 번째 능동 방어선이다. 사용 정책을 강제하고 전체 백엔드 생태계를 보호하는 정교한 트래픽 관리자로서의 역할을 수행한다.15

속도 제한(Rate Limiting) vs. 스로틀링(Throttling)

두 개념은 명확히 구분되어야 한다.
속도 제한 (Rate Limiting): 특정 시간 단위(예: 초당 10만 요청) 내에 허용되는 요청 수에 대한 엄격한 상한선을 설정하는 것이다. 이는 인프라 전체가 감당할 수 없는 트래픽으로부터 시스템을 보호하기 위한 전역적인 조치다. 한도를 초과하는 요청은 즉시 HTTP 429 Too Many Requests 상태 코드로 거부된다.18
스로틀링 (Throttling): 종종 클라이언트 단위(IP 주소 또는 사용자 ID 기준)로 적용되는 더 세밀한 제어 방식이다. 이는 특정 주체의 과도한 요청으로 인한 시스템 남용을 방지하고 공정한 자원 사용을 보장하는 데 목적이 있다. 스로틀링은 요청을 즉시 거부하기보다는 처리 속도를 늦추는 방식으로 동작할 수 있다.17

알고리즘 선택: 토큰 버킷(Token Bucket) vs. 리키 버킷(Leaky Bucket)

토큰 버킷 (Token Bucket): 이 알고리즘은 버킷 용량까지의 순간적인 트래픽 폭증(burst)을 허용하므로, 쿠폰 이벤트와 같이 예측된 트래픽 급증에 대응하는 데 이상적이다. 토큰이 일정한 속도로 버킷에 채워지고, 각 요청은 토큰 하나를 소모한다. 사용 가능한 토큰이 없으면 요청은 거부된다.18 본 시나리오에서는 이 방식이 권장된다.
리키 버킷 (Leaky Bucket): 요청을 일정한 속도로 처리하여 트래픽을 평탄화한다. 초과된 요청은 큐에 대기하거나 버려진다. 이는 합법적인 트래픽 폭증을 처리해야 하는 본 사용 사례에는 덜 적합하다.18

2.2. 로드 밸런싱과 수평적 확장


부하 분산

API 게이트웨이를 통과한 요청들은 로드 밸런서에 의해 다수의 동일하고 상태가 없는(stateless) 애플리케이션 서버들로 분산된다.11 이는 단일 서버가 병목 지점이 되는 것을 방지하고 시스템 전체의 처리 용량을 극대화한다.

확장 전략

본 아키텍처는 수직적 확장(scale-up, 서버 사양 향상) 대신 수평적 확장(scale-out, 서버 수 증가)에 의존한다. 수평적 확장은 비용 효율성이 더 높고, 더 나은 고가용성을 제공하기 때문이다.12 이벤트 시작 전에 부하 테스트를 통해 예측된 트래픽에 맞춰 애플리케이션 서버의 수를 미리 확장해 두는 것이 좋다.

로드 밸런싱 알고리즘

라운드 로빈(Round Robin)이나 최소 연결(Least Connections)과 같은 알고리즘을 사용할 수 있으며, 현재 연결 수가 가장 적은 서버로 트래픽을 보내는 최소 연결 방식이 더 효과적일 수 있다.36

2.3. Thundering Herd 문제 완화


문제 정의

'Thundering Herd' 문제는 특정 이벤트가 발생했을 때 대기 중이던 수많은 스레드나 프로세스가 동시에 깨어나 단일 자원을 놓고 경쟁하면서, 막대한 컨텍스트 스위칭 비용과 시스템 성능 저하를 유발하는 현상을 말한다.10 본 시나리오는 이 문제의 전형적인 예시다.

아키텍처적 완화 전략

본 아키텍처 전체가 이 문제를 완화하도록 설계되었다. 특히 API 게이트웨이의 속도 제한 기능이 가장 핵심적인 역할을 수행한다. 시스템이 안정적으로 처리할 수 있는 임계치 이상의 요청을 사전에 차단함으로써, 후방 시스템이 제어 불가능한 경쟁 상태에 빠지는 것을 원천적으로 방지한다.

클라이언트 측 전략 (지터, Jitter)

서버 측 제어가 가장 중요하지만, 클라이언트 측에서도 시스템 안정성에 기여할 수 있다. 초기 요청이 실패했을 경우(예: 429 또는 503 오류 수신), 재시도 시 임의의 지연 시간(jitter)을 추가한 지수 백오프(exponential backoff) 전략을 구현하도록 권장할 수 있다. 이는 수많은 클라이언트가 동시에 재시도하여 또 다른 트래픽 파도를 만드는 것을 방지하고, 요청을 시간적으로 분산시키는 효과를 가져온다.34
이러한 최전선 방어 메커니즘은 단순히 성능 향상을 위한 것이 아니라, 시스템의 경제적 효율성과 안정성을 위한 필수 요소이다. 악의적이거나 과도한 트래픽을 가장 저렴한 비용으로 처리할 수 있는 계층(에지/게이트웨이)에서 차단함으로써, 애플리케이션 및 데이터베이스 계층의 값비싼 컴퓨팅 자원이 낭비되는 것을 막는다.14 100만 동시 요청이라는 절대적인 최대치를 모두 처리하도록 전체 스택을 과도하게 프로비저닝하는 것은 엄청난 비용을 초래한다.11 따라서, 백엔드는 '지속 가능한' 최대 부하(예: 초당 10만 요청)를 처리하도록 프로비저닝하고, API 게이트웨이를 통해 이 한도를 강제하는 것이 훨씬 비용 효율적인 전략이다. 이는 또한 시스템 안정성을 보장한다. 속도 제한이 없다면, 요청의 홍수가 연쇄적인 장애를 일으켜 1,000명의 정당한 당첨자조차 쿠폰을 받지 못하는 상황이 발생할 수 있다.22 속도 제한 장치는 전체 시스템을 위한 서킷 브레이커(circuit breaker) 역할을 수행하는 것이다.

섹션 3: 핵심 로직 엔진: Redis를 이용한 원자적 발급

이 섹션은 시스템의 심장부로서, 실제 쿠폰 발급 결정이 동시성에 안전한 방식으로 이루어지는 핵심 로직을 다룬다.

3.1. 인메모리 데이터 저장소 선택의 근거


속도에 대한 요구

동기식 응답 요구사항은 핵심 트랜잭션 처리에 있어 밀리초 이하의 지연 시간을 강제한다. 디스크 기반의 전통적인 RDBMS는 잠금(locking) 오버헤드와 I/O 지연 시간 때문에 이러한 높은 경쟁 상태에서 요구되는 성능을 충족시킬 수 없다.11

최적의 선택으로서의 Redis

Redis는 싱글 스레드 기반으로 동작하는 인메모리 데이터 구조 서버로, 데이터 타입에 대한 원자적 연산을 보장한다. 이는 높은 처리량이 요구되는 환경에서 잠금 없이 동시성을 제어하는 데 가장 이상적인 도구이다.13

3.2. 동시성 제어를 위한 Redis 데이터 모델링


재고 관리

단일 키를 사용하여 쿠폰 재고를 표현한다.
키 (Key): coupon:event_id:stock
타입 (Type): String (카운터로 사용)
연산 (Operation): DECR 또는 DECRBY. 이 연산은 원자적이다. 즉, 값을 감소시키고 그 결과를 반환하는 과정이 중단 없이 단일 단계로 이루어진다. 반환된 값이 0 이상인지 확인하여 쿠폰 획득 성공 여부를 판단할 수 있다.27

중복 참여 방지

Redis의 Set 자료구조를 사용하여 이미 참여한 사용자를 추적한다.
키 (Key): coupon:event_id:participants
타입 (Type): Set
연산 (Operation): SADD user_id. 이 명령어는 user_id를 Set에 추가한다. 만약 user_id가 새롭게 추가되었다면 1을, 이미 존재했다면 0을 원자적으로 반환한다. 이는 O(1) 시간 복잡도로 중복 여부를 완벽하게 확인할 수 있는 메커니즘을 제공한다.43

3.3. Lua 스크립트를 통한 원자성 보장


경쟁 상태(Race Condition) 문제

재고 확인과 참여자 확인이라는 두 가지 검사를 애플리케이션 서버에서 순차적으로 실행하는 것은 안전하지 않다. 두 Redis 호출 사이의 네트워크 지연 시간 동안 경쟁 상태가 발생할 수 있다. 예를 들어, 동일한 사용자의 두 요청이 동시에 '아직 참여하지 않음'을 확인한 후, 한 요청이 사용자를 Set에 추가하기 전에 다른 요청이 재고를 감소시키려 시도할 수 있다.

해결책으로서의 Lua 스크립팅

Redis는 서버 측에서 Lua 스크립트를 실행하는 기능을 제공하며, 이 스크립트들은 원자적으로 실행된다. 스크립트가 실행되는 동안 다른 어떤 Redis 명령어 나 스크립트도 실행될 수 없으므로, 스크립트 내의 연산 순서는 분리될 수 없는 단일 트랜잭션으로 보장된다.41

쿠폰 발급 Lua 스크립트 (상세 분석)


Lua


-- KEYS: 참여자 Set 키 (예: "coupon:event_123:participants")
-- KEYS: 재고 카운터 키 (예: "coupon:event_123:stock")
-- ARGV: 쿠폰을 요청하는 사용자 ID

-- 1. 사용자가 이미 참여자 Set에 있는지 확인
local isMember = redis.call('SISMEMBER', KEYS, ARGV)
if isMember == 1 then
  return 1 -- 상태 코드 1: 이미 참여함
end

-- 2. 재고 확인
local stock = tonumber(redis.call('GET', KEYS))
if stock == nil or stock <= 0 then
  return 2 -- 상태 코드 2: 재고 소진
end

-- 3. 재고 감소
redis.call('DECR', KEYS)

-- 4. 사용자를 참여자 Set에 추가
redis.call('SADD', KEYS, ARGV)

return 0 -- 상태 코드 0: 성공



스크립트 분석

이 스크립트는 키와 인자를 외부에서 받아 재사용성과 효율성을 높인다.48
애플리케이션 서버가 쉽게 해석하여 동기식 HTTP 응답(성공, 중복 참여, 재고 소진)을 생성할 수 있도록 명확한 숫자 코드를 반환한다.
애플리케이션 서버에서 Redis로의 단 한 번의 EVALSHA 호출이 전체 임계 영역(critical section)을 캡슐화한다. 이는 검사 단계 사이의 네트워크 지연을 제거하고, 복잡한 분산 잠금 없이 원자성을 보장하는 가장 효율적인 방법이다.49

3.4. Redis 고가용성 보장


단일 장애점(Single Point of Failure) 문제

단일 Redis 노드는 시스템 전체를 중단시킬 수 있는 치명적인 단일 장애점이다.

Redis Sentinel

모니터링과 자동 장애 복구(failover)를 통해 고가용성을 제공한다. 여러 Sentinel 프로세스가 프라이머리-레플리카(primary-replica) 구조의 클러스터를 감시하다가 프라이머리 노드에 장애가 발생하면, 레플리카 중 하나를 새로운 프라이머리로 승격시킨다.51 이는 중간 규모의 시스템에 적합하다.

Redis Cluster

데이터를 여러 프라이머리 노드에 분산 저장(sharding)함으로써 고가용성과 확장성을 동시에 제공한다. 각 프라이머리 노드는 자체 레플리카를 가질 수 있다.26 100만 사용자 규모의 이벤트를 위해서는 Redis Cluster가 권장되는 아키텍처다. 더 높은 처리량을 감당할 수 있으며, 샤드(shard) 수준의 장애 허용성을 제공한다. 한 샤드의 프라이머리가 다운되더라도, 장애 복구가 진행되는 동안 해당 샤드의 데이터만 일시적으로 사용 불가능할 뿐, 클러스터의 나머지 부분은 정상적으로 동작한다.

배포 전략

데이터 센터 수준의 장애로부터 시스템을 보호하기 위해 Redis Cluster를 여러 가용 영역(Multi-AZ)에 걸쳐 배포하는 것이 필수적이다.54
이처럼 Redis의 데이터 구조 선택과 Lua 스크립팅의 활용은 단순한 성능 최적화를 넘어, 올바른 동시성 제어를 가능하게 하는 근본적인 요소이다. 이는 복잡하고, 느리며, 오류 발생 가능성이 높은 분산 잠금 메커니즘을 단순하고, 고성능이며, 정확성이 증명된 대안으로 대체한다. 핵심 문제는 '확인 후 실행(check-then-act)'이라는 동시성 연산이다. 분산 시스템에서 잠금 없는 '확인 후 실행'은 전형적인 경쟁 상태 안티패턴이다.39 전통적인 해결책은 분산 잠금을 사용하는 것이지만, 이는 '즉각적인 응답' 요구사항을 위반하는 심각한 지연 시간과 복잡성을 초래한다.50 Redis의 개별 명령어(
SADD, DECR)는 원자적이지만 40, 클라이언트에서 이들을 순차적으로 호출할 경우 네트워크 왕복 시간 때문에 전체 시퀀스의 원자성은 보장되지 않는다. 이 논리적 흐름은 서버 측에서 명령어 시퀀스를 원자적으로 실행할 메커니즘의 필요성으로 귀결되며, 이것이 바로 Redis에서 Lua 스크립팅이 제공하는 핵심 기능이다.45 따라서 Lua 스크립트는 '있으면 좋은 것'이 아니라, 엄격한 성능 제약 조건 하에서 핵심 동시성 문제를 해결하는 결정적인 부품, 즉 전체 동기식 경로의 린치핀(linchpin)이다.

섹션 4: 분리와 내구성: 비동기 영속성 계층

이 섹션에서는 클라이언트 대면 응답 속도를 저하시키지 않으면서 시스템이 어떻게 데이터의 영속성을 달성하는지 설명한다.

4.1. 동기/비동기 경계 정의


경계의 설정

동기/비동기 처리의 경계는 Redis Lua 스크립트의 성공적인 실행 직후에 그어진다. 동기식 경로에서 애플리케이션 서버의 책임은 (a) Redis로부터 성공 코드를 수신하고, (b) 영속화를 위한 메시지를 메시지 큐에 성공적으로 전송하는 것으로 끝난다.6

Write-Behind 캐싱 패턴

이 아키텍처는 전형적인 'Write-Behind' 캐싱 패턴의 구현이다. 캐시(Redis)가 먼저 업데이트되고, 백업 저장소(RDBMS)로의 쓰기 작업은 지연되어 비동기적으로 처리된다. 이는 쓰기 성능을 최적화하지만, 데이터가 영속화되기 전에 캐시(Redis)에 장애가 발생할 경우 극히 짧은 시간 동안 데이터 유실 가능성을 내포한다.57 안정적인 메시지 큐를 사용함으로써 이 위험을 크게 완화할 수 있다.

4.2. 안정적인 쓰기를 위한 메시지 큐


영속적인 버퍼로서의 역할

Apache Kafka나 AWS SQS와 같은 메시지 큐는 높은 처리량의 애플리케이션 서버와 상대적으로 낮은 처리량의 RDBMS 사이에서 영속적인 버퍼 역할을 한다.5

부하 평탄화 (Load Leveling)

이벤트가 진행되는 동안 수백만 건의 요청이 단 몇 초 만에 1,000건의 성공적인 발급으로 이어질 수 있다. 메시지 큐는 이처럼 폭발적으로 발생하는 '쓰기' 이벤트를 흡수하고, 컨슈머 서비스가 큐를 안정적이고 관리 가능한 속도로 처리하여 데이터베이스에 쓰도록 함으로써 데이터베이스가 과부하되는 것을 방지한다.5

기술 선택 (Kafka vs. RabbitMQ/SQS)

Kafka: 추가 전용 로그(append-only log) 구조로, 높은 처리량의 이벤트 스트리밍과 데이터 내구성에 매우 뛰어나다. 메시지를 재생(replay)할 수 있는 기능은 장애 복구나 감사(auditing) 시 큰 이점을 제공한다.60 본 시스템의 규모에서는 Kafka가 권장된다.
RabbitMQ/SQS: 전통적인 메시지 브로커로, 기본적인 큐잉 작업에는 훌륭한 선택지이다. 관리 측면에서 더 단순할 수 있다.62 기존 인프라와 팀의 전문성에 따라 선택할 수 있다.

4.3. 데드 레터 큐(DLQ)를 이용한 장애 처리


DLQ의 목적

데드 레터 큐(Dead Letter Queue, DLQ)는 컨슈머가 특정 횟수만큼 재시도한 후에도 처리에 실패한 메시지를 보내는 보조 큐이다.63

시나리오

데이터베이스가 일시적으로 사용 불가능하거나, 컨슈머 코드의 버그로 인해 반복적으로 실패를 유발하는 '독성 메시지(poison pill)'가 발생했다고 가정해 보자. DLQ가 없다면 이 메시지는 무한정 재시도되면서 후속으로 들어오는 모든 정상적인 메시지의 처리를 막을 수 있다.

구현

컨슈머 서비스는 재시도 정책(예: 지수 백오프를 사용한 3회 재시도)을 갖도록 구성된다. 만약 메시지가 모든 재시도에 실패하면, DLQ로 이동된다. 이때 운영팀에게 경고(alert)가 발생하여 엔지니어가 실패한 메시지와 오류 내용을 조사하고, 근본적인 문제(예: DB 복구, 코드 수정 배포)를 해결한 후, DLQ에 있는 메시지를 수동 또는 자동으로 다시 메인 큐로 보내 재처리를 시도할 수 있다.66 이는 일시적인 백엔드 장애로 인해 성공적으로 발급된 쿠폰 정보가 영구적으로 유실되는 것을 방지한다.
메시지 큐와 DLQ는 단순한 성능 향상 도구가 아니라, 시스템의 복원력과 최종적 일관성을 달성하기 위한 근본적인 구성 요소이다. 이들은 깨지기 쉬운 강결합(tightly-coupled) 시스템을 견고하고 장애 허용적인 시스템으로 변환한다. 아키텍처는 '결정'(Redis에서)과 '기록'(RDBMS에서)을 분리했다. 만약 기록 과정이 실패하면 어떻게 될까? 강결합 시스템에서는 전체 트랜잭션을 롤백해야 하며, 이는 복잡하고 느리다. 하지만 분리된 시스템에서는 사용자가 이미 '성공' 응답을 받았으므로 이를 되돌릴 수 없다. 따라서 시스템은 성공적인 결정이 '결국에는' 기록될 것임을 보장해야 하며, 이것이 바로 최종적 일관성에 대한 요구사항이다.
메시지 큐는 1차적인 내구성을 제공한다. 메시지가 Kafka 브로커에 의해 확인(acknowledge)되면, 해당 메시지를 생성한 애플리케이션 서버가 다운되더라도 안전하다.28 그러나 데이터베이스에 쓰는 컨슈머 서비스 또한 실패할 수 있다. 데이터베이스가 다운되거나, 네트워크 단절이 발생하거나, 메시지 데이터 자체가 잘못되었을 수 있다. 단순한 재시도는 일시적인 문제를 해결할 수 있지만, 큐를 막아버리는 영구적인 장애나 독성 메시지는 처리할 수 없다.5 이 지점에서 데드 레터 큐 패턴의 필요성이 명확해진다. DLQ는 문제가 되는 메시지를 격리하여 나머지 큐가 계속 처리될 수 있도록 함으로써, 유효한 메시지에 대한 영속성 파이프라인의 가용성을 유지한다. 따라서 DLQ는 데이터 손실이나 처리 중단 없이 영속성 장애로부터 시스템이 복구될 수 있도록 보장하는, 복원력을 위한 핵심 요소이다.

섹션 5: 최종 기록 저장소: 데이터베이스와 최종적 일관성

이 마지막 섹션에서는 시스템의 최종 상태가 정확하고 신뢰할 수 있도록 보장하는 영구 저장 계층과 관련 프로세스를 상세히 설명한다.

5.1. 관계형 데이터베이스 스키마 설계


RDBMS 선택의 근거

PostgreSQL이나 MySQL과 같은 관계형 데이터베이스(RDBMS)는 강력한 일관성 보장(ACID 준수)과 제약 조건을 통한 데이터 무결성 강제 능력 때문에 최종 기록 저장소(system of record)로 선택된다.29

제안된 데이터베이스 스키마 표

명확한 스키마는 데이터 무결성의 기초이다. 아래 표는 이벤트 결과를 정확하게 기록하고 최하위 계층에서 데이터 이상 현상을 방지하는 데 필요한 데이터 모델, 관계, 제약 조건을 명시적으로 정의한다.
테이블명
컬럼명
데이터 타입
제약 조건/인덱스
설명
coupons
id
INT
PRIMARY KEY
쿠폰 이벤트의 고유 식별자


event_name
VARCHAR(255)
NOT NULL
프로모션 이벤트의 이름


total_quantity
INT
NOT NULL
초기 쿠폰 재고 수량 (예: 1000)


created_at
TIMESTAMP


생성 시각
coupon_issuances
id
BIGINT
PRIMARY KEY
각 발급 건의 고유 식별자


coupon_id
INT
FOREIGN KEY (coupons.id)
쿠폰 이벤트를 참조


user_id
VARCHAR(255)
UNIQUE, NOT NULL
쿠폰을 발급받은 사용자의 고유 ID


coupon_code
VARCHAR(50)
UNIQUE, NOT NULL
사용자에게 지급된 실제 쿠폰 코드


issued_at
TIMESTAMP
NOT NULL
발급 시각


무결성 제약 조건

coupon_issuances 테이블의 user_id 컬럼에 대한 UNIQUE 제약 조건은 매우 중요하다. 이는 애플리케이션 계층에서 발생할 수 있는 모든 경쟁 상태나 재처리 이슈에 대한 최종적이고 결정적인 안전장치 역할을 하여, '사용자당 하나의 쿠폰'이라는 비즈니스 규칙이 데이터베이스 수준에서 강제되도록 보장한다.30

5.2. 컨슈머 서비스와 멱등성(Idempotent) 쓰기


기능

컨슈머 서비스는 큐에서 메시지를 읽어 coupon_issuances 테이블에 데이터를 삽입하는 책임만을 지는, 독립적이고 상태 없는 워커 서비스(예: Kubernetes 디플로이먼트 또는 Lambda 함수)이다.19

'최소 한 번' 전송(At-Least-Once Delivery)의 문제

대부분의 메시지 큐 시스템은 '최소 한 번' 전송을 보장한다. 이는 특정 장애 상황(예: 컨슈머가 DB에 쓰기 작업을 완료했지만 메시지 확인(ack) 신호를 보내기 전에 다운되는 경우)에서 동일한 메시지가 다시 전달되어 처리될 수 있음을 의미한다.5

멱등성 보장

컨슈머의 쓰기 연산은 반드시 멱등성(idempotent)을 가져야 한다. 즉, 연산을 여러 번 실행해도 한 번 실행한 것과 동일한 결과를 내야 한다. 데이터베이스 스키마의 user_id에 대한 UNIQUE 제약 조건이 자연스럽게 이를 강제한다. 만약 컨슈머가 이미 존재하는 user_id에 대한 레코드를 다시 삽입하려고 시도하면, 데이터베이스는 제약 조건 위반 오류를 발생시킨다. 컨슈머는 이 특정 오류를 포착하여 해당 메시지가 이미 성공적으로 처리된 것으로 간주하고 안전하게 메시지를 확인(ack) 처리함으로써 중복 레코드가 생성되는 것을 방지할 수 있다.28

5.3. 데이터 정합성 검증 및 감사


이벤트 후 검증

이벤트가 종료된 후, 데이터 무결성을 검증하기 위한 정합성 검증(reconciliation) 프로세스를 실행해야 한다.

검증 항목

coupon_issuances 테이블의 총 레코드 수(COUNT(*))는 Redis에 기록된 재고 감소분(초기 재고 - 최종 재고)과 일치해야 한다.
coupon_issuances 테이블의 고유한 user_id 수는 전체 레코드 수와 일치해야 한다.

신뢰의 원천 (Source of Truth)

어떤 사용자가 공식적으로 쿠폰을 받았는지에 대한 최종적인 신뢰의 원천은 RDBMS이다. Redis의 데이터는 일시적인 상태 정보로 간주될 수 있으며, 모든 데이터가 RDBMS에 완전히 영속화되고 정합성 검증이 완료된 후에는 정리될 수 있다.
이 분산 시스템에서의 데이터 무결성은 단일 메커니즘이 아닌, 계층화된 방어 전략을 통해 달성된다. 각 계층(Redis의 원자성, 메시지 큐의 내구성, 데이터베이스의 제약 조건)은 서로 다른 종류의 보증을 제공하며, 이들이 함께 어우러져 매우 신뢰성 높은 시스템을 구축한다. 첫 번째 방어 계층은 결정의 순간에 논리적 경쟁 상태를 방지하는 Redis Lua 스크립트이다.50 그러나 이것만으로는 데이터 저장이 보장되지 않는다. 두 번째 계층은 애플리케이션 서버의 장애나 일시적인 네트워크 문제로 인한 성공적인 발급 '이벤트'의 손실을 막는 안정적인 메시지 큐이다.28 세 번째 계층은 컨슈머의 재시도 로직과 DLQ로, 영구적이지만 복구 가능한 처리 실패로 인한 이벤트 손실을 방지한다.63 마지막이자 가장 절대적인 방어 계층은 데이터베이스의
UNIQUE 제약 조건이다.30 이 제약 조건은 '사용자당 하나의 쿠폰'이라는 비즈니스 규칙에 대한 궁극적인 보증을 제공하며, 이전 계층들에서 예기치 않게 발생할 수 있는 버그나 엣지 케이스(예: 중복 메시지 생성)에 대한 안전장치 역할을 한다. 이는 '심층 방어(defense in depth)' 원칙이 데이터 일관성에 적용된 사례로, 시스템이 단일 지점의 강제성에 의존하지 않고 여러 보완적인 메커니즘을 사용하여 초기 고속 트랜잭션부터 최종 영구 기록에 이르기까지 정확성을 보장함을 보여준다.

섹션 6: 결론 및 전략적 권장 사항


아키텍처 요약

본 보고서에서 제안한 하이브리드 동기/비동기 아키텍처는 즉각적인 피드백, 대규모 동시성 처리, 그리고 엄격한 데이터 무결성이라는 핵심 요구사항을 성공적으로 해결한다. 시스템의 최전선에서는 API 게이트웨이와 로드 밸런서를 통해 트래픽을 제어하고, 핵심 로직은 Redis의 원자적 연산을 통해 신속하고 안전하게 처리된다. 마지막으로, 메시지 큐를 이용한 비동기 영속성 계층은 시스템의 응답성을 저해하지 않으면서 데이터의 최종적 일관성과 안정성을 보장한다.

핵심 교훈

하이브리드 모델의 채택: 이 문제에 대해 순수 동기식 아키텍처를 시도해서는 안 된다. 성능을 위해서는 영속성 처리의 분리가 필수적이다.
원자성의 중요성: 공유 자원에 대한 경쟁을 관리하기 위해 서버 측 원자적 연산(예: Redis Lua 스크립트)을 사용해야 한다. 클라이언트 측의 '확인 후 실행' 로직이나 복잡한 분산 잠금은 피해야 한다.
에지에서의 트래픽 제어: 시스템의 안정성은 API 게이트웨이에서의 선제적인 속도 제한과 스로틀링에 달려있다. 빠르고 저렴하게 실패시키는 것이 중요하다.
장애를 고려한 설계: 모든 핵심 계층(Redis Cluster, Multi-AZ 배포, DLQ를 포함한 컨슈머 재시도 로직)에서 고가용성을 구현해야 한다.

최종 권장 사항

본 아키텍처를 성공적으로 구현하기 위해 다음의 사항들을 강력히 권장한다.
철저한 부하 테스트: 이벤트 시작 전, 포괄적인 부하 테스트를 수행하여 속도 제한 임계치를 정밀하게 조정하고, 필요한 인프라 자원을 사전에 확장해야 한다.
강력한 모니터링 및 경고 시스템 구축: 메시지 큐의 깊이(queue depth), DLQ에 쌓이는 메시지 수, Redis의 성능 지표(CPU, 메모리, 지연 시간) 등을 실시간으로 모니터링하고, 이상 징후 발생 시 즉시 경고를 받을 수 있는 체계를 구축해야 한다.
클라이언트 측의 우아한 실패 처리: 클라이언트 애플리케이션이 서버로부터 429 Too Many Requests나 503 Service Unavailable과 같은 오류 응답을 받았을 때, 사용자에게 적절한 메시지를 표시하고 무분별한 재시도를 하지 않도록 우아하게 실패를 처리하는 로직을 구현해야 한다.